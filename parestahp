#!/usr/bin/env python3
from collections import defaultdict, Counter
from sys import exit, stderr, stdout, stdin
import os
from os import path

import gffutils
from intervaltree import IntervalTree, Interval
import numpy as np
import pysam

import docopt


CLI = """
parestahp -- Histogram coverage of 5' PARE data around stop sites

USAGE:
    parestahp [options] -g GFF_FILE BAMFILE

OPTIONS:
    -P          Output counts per gene
    -u INT      Count INT bases upstream of the stop [default: 100]
    -d INT      Count INT bases downstream stream of the stop [default: 100]
    -g GFFFILE  GFF file describing gene models.
    -l GENIDS   File containing a list of gene models. If not given, all gene
                models are used, which can create inaccuate results. Please
                provide a list of representative gene models.
"""

# Copyright (c) 2016-2017 Kevin Murray <kdmfoss@gmail.com>

# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.


def progprint(*args):
    print(*args, file=stderr, flush=True)


def load_gffdb(gfffile):
    '''Loads GFF from `gfffile` into in-memory SQLite db and returns cursor.'''

    if gfffile.endswith(".sqlite"):
        progprint("Using cached annotation database")
        return gffutils.FeatureDB(gfffile)
    progprint("Loading annotation into database")
    db = gffutils.create_db(gfffile, ":memory:")
    progprint("\t... Finished!")
    return db


def make_roi_trees(gfffile, transcript_ids=None, upstream=100, downstream=50):
    '''With apologies to K&R, /* You are not supposed to understand this */'''
    gffdb = load_gffdb(gfffile)

    # ROIs are 1 tree for fwd & rev per chromosome
    roi_fs = defaultdict(IntervalTree)
    roi_rs = defaultdict(IntervalTree)

    # Default to all mRNA IDs
    if transcript_ids is None:
        mrnas = gffdb.all_features(featuretype='mRNA')
        transcript_ids = [m.id for m in mrnas]

    progprint("Loading transcripts from DB into ROI trees")
    i = 0
    for i, transcript_id in enumerate(transcript_ids):
        if (i % 5000) == 0:
            progprint("\t...", i)

        transcript = gffdb[transcript_id]

        if transcript.featuretype != 'mRNA':
            continue

        chrom = transcript.chrom
        roi_f = roi_fs[chrom]
        roi_r = roi_rs[chrom]

        cdses = list(gffdb.children(transcript_id, featuretype='CDS', order_by='start'))
        total_captured = 0
        if transcript.strand == '+':
            for cds in reversed(cdses):
                to_capture = min(upstream - total_captured, len(cds))
                if to_capture <= 0:
                    break
                # left of the end by length to capture. Note the start is 0-based, for BED indexing
                roi_start = cds.end - to_capture
                roi_end = cds.end
                roi_f[roi_start:roi_end] = {'win_start': -(total_captured+to_capture+1),
                                            'tid': transcript.id,
                                            'type': 'cds'}
                total_captured += to_capture
        elif transcript.strand == '-':
            for cds in cdses:
                to_capture = min(upstream - total_captured, len(cds))
                if to_capture <= 0:
                    break
                # Note the -1s are for BED indexing
                roi_start = cds.start - 1
                roi_end = cds.start + to_capture - 1
                roi_r[roi_start:roi_end] = {'win_start': -1,
                                            'tid': transcript.id,
                                            'type': 'cds'}
                total_captured += to_capture

        # Deal with downstream from stop codon, i.e. 3' UTR
        utr = list(gffdb.children(transcript_id, featuretype='three_prime_UTR'))
        if len(utr) < 1:
            # Some transcripts have no UTR
            continue
        utr = utr[0]
        to_capture = min(downstream, len(utr))
        if transcript.strand == '+':
            # left of the end by length to capture. Note the start is 0-based, for BED indexing
            roi_start = utr.start - 1
            roi_end = utr.start + to_capture - 1
            roi_f[roi_start:roi_end] = {'win_start': 0,
                                        'tid': transcript.id,
                                        'type': 'utr'}
        elif transcript.strand == '-':
            roi_start = utr.end - to_capture
            roi_end = utr.end
            roi_r[roi_start:roi_end] = {'win_start': to_capture - 1,
                                        'tid': transcript.id,
                                        'type': 'utr'}
    progprint("\t... Finished, {:,} reads".format(i))
    return roi_fs, roi_rs


def processs_bam(bamfile, roi_trees, upstream=100, downstream=50):
    bam = pysam.AlignmentFile(bamfile, "rb")
    gcovs = defaultdict(lambda: np.zeros(upstream + downstream))
    fwdtree, revtree = roi_trees
    i = 0
    for i, read in enumerate(bam):
        if (i % 1000000) == 0:
            progprint("\t... {:0.0f}M reads".format(i / 1e6))

        # skip weird or bad reads
        if read.is_unmapped or read.is_duplicate or read.is_paired or \
                read.is_secondary or read.is_supplementary:
            continue

        chrom = read.reference_name
        if read.is_reverse:
            roi_tree = revtree[chrom]
            pos = read.reference_end
        else:
            roi_tree = fwdtree[chrom]
            pos = read.reference_start

        features = list(roi_tree[pos])
        if len(features) != 1:
            continue
        feature = features[0]
        locus = feature.data["tid"]
        if not read.is_reverse:
            windowpos = pos-(feature.begin) + feature.data['win_start']
        else:
            windowpos = feature.begin - pos + feature.data['win_start']
        windowpos += upstream

        gcovs[locus][windowpos] += 1
    progprint("\t... Finished, {:,} reads".format(i))
    bam.close()
    return gcovs


def calc_sum_all_transcripts(coverage):
    all = None
    for tx_vals in coverage.values():
        if all is None:
            all = np.zeros_like(tx_vals)
        all += tx_vals
    return all


def print_histogram(coverage, upstream, downstream, per_gene=False):
    all = calc_sum_all_transcripts(coverage)

    print("locus", *["pos_{}".format(i) for i in range(-upstream, downstream)],
          sep='\t')
    print("ALL", *list(all), sep='\t')

    if per_gene:
        for tx_id, coverage in sorted(coverage.items()):
            print(tx_id, *list(coverage), sep='\t')


def parse_txlist(txfile):
    with open(txfile) as fh:
        txlist = set()
        for line in fh:
            tx = line.rstrip()
            if tx:
                txlist.add(tx)
    return txlist


def main():
    args = docopt.docopt(CLI)

    gff = args['-g']
    if args['-l']:
        txlist = parse_txlist(args['-l'])
        progprint("Extracting", len(txlist), "transcripts")
    else:
        txlist = None
        progprint("Extracting all transcripts")
    upstream = int(args['-u'])
    downstream = int(args['-d'])

    progprint("Looking", upstream, "base upstream of TSS")
    progprint("Looking", downstream, "base downstream of TSS")

    progprint("Starting computation")

    progprint("Make ROI trees ...")
    roi_trees = make_roi_trees(gff, txlist, upstream, downstream)
    progprint("Make ROI trees ... done")

    progprint("Calculate 5'PARE histograms ...")
    coverage = processs_bam(args['BAMFILE'], roi_trees, upstream, downstream)
    progprint("Calculate 5'PARE histograms ... done")
    print_histogram(coverage, upstream, downstream, per_gene=args["-P"])

    progprint("Finished!")


if __name__ == "__main__":
    main()
