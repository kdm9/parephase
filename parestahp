#!/usr/bin/env python3
from collections import defaultdict
from sys import exit, stderr, stdout, stdin

import gffutils
from intervaltree import IntervalTree, Interval
import numpy as np
import scipy as sp
import pysam

import docopt

CLI = """
parestahp -- Histogram coverage of 5' PARE data around stop sites

USAGE:
    parestahp [options] -g GFF_FILE BAMFILE

OPTIONS:
    -u INT      Count INT bases upstream of the stop [default: 100]
    -d INT      Count INT bases downstream stream of the stop [default: 100]
    -g GFFFILE  GFF file describing gene models.
    -l GENIDS   File containing a list of gene models. If not given, all gene
                models are used, which can create inaccuate results. Please
                provide a list of representative gene models.
"""

# Copyright (c) 2016-2017 Kevin Murray <kdmfoss@gmail.com>

# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.


def load_gffdb(gfffile):
    '''Loads GFF from `gfffile` into in-memory SQLite db and returns cursor.'''
    return gffutils.create_db(gfffile, ":memory:")


def make_roi_trees(gfffile, transcript_ids=None, upstream=100, downstream=50):
    gffdb = load_gffdb(gfffile)
    roi_fs = defaultdict(IntervalTree)
    roi_rs = defaultdict(IntervalTree)
    if transcript_ids is None:
        mrnas = gffdb.all_features(featuretype='mRNA')
        transcript_ids = [m.id for m in mrnas]
    for i, transcript_id in enumerate(transcript_ids):
        if (i % 5000) == 0:
            print("\t...", i, file=stderr)
        transcript = gffdb[transcript_id]
        if transcript.featuretype != 'mRNA':
            continue

        chrom = transcript.chrom
        roi_f = roi_fs[chrom]
        roi_r = roi_rs[chrom]

        cdses = list(gffdb.children(transcript_id, featuretype='CDS', order_by='start'))
        total_captured = 0
        if transcript.strand == '+':
            for cds in reversed(cdses):
                to_capture = min(upstream - total_captured, len(cds))
                if to_capture <= 0:
                    break
                # left of the end by length to capture. Note the start is 0-based, for BED indexing
                roi_start = cds.end - to_capture
                roi_end = cds.end
                roi_f[roi_start:roi_end] = {'win_start': -(total_captured+to_capture),
                                            'win_end': -(total_captured),
                                            'tid': transcript.id,
                                            'type': 'cds'}
                total_captured += to_capture
        elif transcript.strand == '-':
            for cds in cdses:
                to_capture = min(upstream - total_captured, len(cds))
                if to_capture <= 0:
                    break
                # Note the -1s are for BED indexing
                roi_start = cds.start - 1
                roi_end = cds.start + to_capture - 1
                roi_r[roi_start:roi_end] = {'win_start': -(total_captured),
                                            'win_end': -(total_captured+to_capture),
                                            'tid': transcript.id,
                                            'type': 'cds'}
                total_captured += to_capture

        # Deal with downstream from stop codon, i.e. 3' UTR
        utr = list(gffdb.children(transcript_id, featuretype='three_prime_UTR'))
        if len(utr) < 1:
            # Some transcripts seem to have no UTR, is this right?
            continue
        utr = utr[0]
        to_capture = min(downstream, len(utr))
        if transcript.strand == '+':
            roi = roi_f
            # left of the end by length to capture. Note the start is 0-based, for BED indexing
            roi_start = utr.start - 1
            roi_end = utr.start + to_capture - 1
        elif transcript.strand == '-':
            roi = roi_r
            roi_start = utr.end - to_capture
            roi_end = utr.end
        roi[roi_start:roi_end] = {'win_start': 1,
                                  'win_end': to_capture,
                                  'tid': transcript.id,
                                  'type': 'utr'}
    return roi_fs, roi_rs


def iter_bedgraph(filename, minval=0):
    with open(filename) as bed:
        for line in bed:
            rec = line.rstrip("\r\n").split()
            chrm = rec[0]
            start = int(rec[1])
            stop = int(rec[2])
            val = abs(int(rec[3]))
            if val >= minval:
                yield (chrm, range(start, stop), val)


def process_beds(plusbed, minusbed, roi_trees, upstream=100, downstream=50):
    cov = np.zeros(upstream + downstream)
    for roi_tree, bed in zip(roi_trees, (plusbed, minusbed)):
        for chrom, posrange, count in iter_bedgraph(bed, minval=1):
            roi = roi_tree[chrom]
            for pos in posrange:
                features = list(roi[pos])
                if len(features) != 1:
                    continue
                w = features[0]
                windowpos = pos-(w.begin) + w.data['win_start']
                cov[windowpos] += count

    return cov


def processs_bam(bamfile, roi_trees, upstream=100, downstream=50):
    bam = pysam.AlignmentFile(bamfile, "rb")
    bcov = np.zeros(upstream + downstream)
    fwdtree, revtree = roi_trees
    for i, read in enumerate(bam):
        if (i % 1000000) == 0:
            print("\t... {:0.1f}M reads".format(i / 1e6), file=stderr)
        if read.is_unmapped  or read.is_duplicate or read.is_paired or \
                read.is_secondary or read.is_supplementary:
            # skip weird or bad reads
            continue

        ref = read.reference_name
        roi_tree = revtree[ref] if read.is_reverse else fwdtree[ref]
        pos = read.reference_start

        features = list(roi_tree[pos])
        if len(features) != 1:
            continue
        w = features[0]
        windowpos = pos-(w.begin) + w.data['win_start']
        bcov[windowpos] += 1
    bam.close()
    return bcov


def print_histogram(coverage, upstream, downstream):
    for e, i in enumerate(reversed(range(1, upstream+1))):
        print(-i, coverage[e], sep='\t')
    for e, i in enumerate(reversed(range(1, downstream+1)), start=upstream):
        print(i, coverage[e], sep='\t')


def parse_txlist(txfile):
    with open(txfile) as fh:
        txlist = set()
        for line in fh:
            tx = line.rstrip()
            if tx:
                txlist.add(tx)
    return txlist


def main():
    args = docopt.docopt(CLI)

    gff = args['-g']
    if args['-l']:
        txlist = parse_txlist(args['-l'])
        print("Extracting", len(txlist), "transcripts", file=stderr)
    else:
        txlist = None
        print("Extracting all transcripts", file=stderr)
    upstream = int(args['-u'])
    downstream = int(args['-d'])

    print("Looking", upstream, "base upstream of TSS", file=stderr)
    print("Looking", downstream, "base downstream of TSS", file=stderr)

    print("Starting computation", file=stderr)

    print("Make ROI trees ...", file=stderr)
    roi_trees = make_roi_trees(gff, txlist, upstream, downstream)
    print("Make ROI trees ... done", file=stderr)

    print("Calculate 5'PARE histograms ...", file=stderr)
    coverage = processs_bam(args['BAMFILE'], roi_trees, upstream, downstream)
    print("Calculate 5'PARE histograms ... done", file=stderr)
    print_histogram(coverage, upstream, downstream)

    print("Finished!", file=stderr)


if __name__ == "__main__":
    main()
